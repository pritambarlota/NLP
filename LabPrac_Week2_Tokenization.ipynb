{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Tokenizing sentence and words\n",
    "\n",
    "# import the sentence and word tokenization module\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# some sample texts\n",
    "sample_text='''\n",
    "Trump was born and raised in the New York City borough of Queens,\n",
    "and received an economics degree from the Wharton School of the University of\n",
    "Pennsylvania. He took charge of his family's real estate business in 1971,\n",
    "renamed it to The Trump Organization, and expanded it into Manhattan.\n",
    "The company built or renovated skyscrapers, hotels, casinos, and golf courses.\n",
    "Trump later started various side ventures, including licensing his name\n",
    "for real estate and consumer products. He managed the company until his\n",
    "2017 inauguration. He co-authored several books, including The Art of the Deal.\n",
    "He owned the Miss Universe and Miss USA beauty pageants from 1996 to 2015,\n",
    "and he produced and hosted the reality television show The Apprentice from\n",
    "2003 to 2015. Forbes estimates his net worth to be $3.1 billion. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "billion\n",
      "1\n",
      "'s\n",
      "1\n",
      "consumer\n",
      "1\n",
      "Queens\n",
      "1\n",
      "television\n",
      "1\n",
      "borough\n",
      "1\n",
      "show\n",
      "1\n",
      "York\n",
      "1\n",
      "1971\n",
      "1\n",
      "$\n",
      "1\n",
      "into\n",
      "1\n",
      "produced\n",
      "1\n",
      "ventures\n",
      "1\n",
      "in\n",
      "2\n",
      "later\n",
      "1\n",
      "charge\n",
      "1\n",
      "his\n",
      "4\n",
      "side\n",
      "1\n",
      "School\n",
      "1\n",
      "pageants\n",
      "1\n",
      "estimates\n",
      "1\n",
      "University\n",
      "1\n",
      "the\n",
      "7\n",
      "USA\n",
      "1\n",
      "including\n",
      "2\n",
      "of\n",
      "5\n",
      ".\n",
      "8\n",
      "born\n",
      "1\n",
      "Organization\n",
      "1\n",
      "1996\n",
      "1\n",
      "renovated\n",
      "1\n",
      "golf\n",
      "1\n",
      "2003\n",
      "1\n",
      "took\n",
      "1\n",
      "family\n",
      "1\n",
      "Apprentice\n",
      "1\n",
      "casinos\n",
      "1\n",
      "received\n",
      "1\n",
      "hotels\n",
      "1\n",
      "licensing\n",
      "1\n",
      "net\n",
      "1\n",
      "reality\n",
      "1\n",
      "Wharton\n",
      "1\n",
      "was\n",
      "1\n",
      "several\n",
      "1\n",
      "The\n",
      "4\n",
      "renamed\n",
      "1\n",
      "estate\n",
      "2\n",
      "He\n",
      "4\n",
      "skyscrapers\n",
      "1\n",
      "managed\n",
      "1\n",
      "New\n",
      "1\n",
      "inauguration\n",
      "1\n",
      "worth\n",
      "1\n",
      "Miss\n",
      "2\n",
      "an\n",
      "1\n",
      "until\n",
      "1\n",
      "to\n",
      "4\n",
      "hosted\n",
      "1\n",
      "and\n",
      "8\n",
      "Manhattan\n",
      "1\n",
      "economics\n",
      "1\n",
      "it\n",
      "2\n",
      "3.1\n",
      "1\n",
      "expanded\n",
      "1\n",
      "books\n",
      "1\n",
      "various\n",
      "1\n",
      "from\n",
      "3\n",
      "Forbes\n",
      "1\n",
      "started\n",
      "1\n",
      "beauty\n",
      "1\n",
      "owned\n",
      "1\n",
      "products\n",
      "1\n",
      "Deal\n",
      "1\n",
      "courses\n",
      "1\n",
      "degree\n",
      "1\n",
      "City\n",
      "1\n",
      "2017\n",
      "1\n",
      "built\n",
      "1\n",
      "Trump\n",
      "3\n",
      "company\n",
      "2\n",
      "Universe\n",
      "1\n",
      "business\n",
      "1\n",
      "name\n",
      "1\n",
      "raised\n",
      "1\n",
      "co-authored\n",
      "1\n",
      "Art\n",
      "1\n",
      ",\n",
      "9\n",
      "real\n",
      "2\n",
      "be\n",
      "1\n",
      "or\n",
      "1\n",
      "he\n",
      "1\n",
      "2015\n",
      "2\n",
      "for\n",
      "1\n",
      "Pennsylvania\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fre = []\n",
    "word_list = nltk.word_tokenize(sample_text)\n",
    "dis_word_list = set(word_list)\n",
    "for i in dis_word_list:\n",
    "    print(i)\n",
    "    print(word_list.count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.probability.FreqDist'>\n",
      "dog -> 4\n",
      "cat -> 2\n",
      "snake -> 1\n",
      "dog\n",
      "[('dog', 4), ('cat', 2)]\n"
     ]
    }
   ],
   "source": [
    "text2 = ['dog','dog','cat','cat','dog','dog','snake']\n",
    "fDist = nltk.FreqDist(text2)\n",
    "print(type(fDist))\n",
    "for i in fDist:\n",
    "    print(i, '->', fDist[i])\n",
    "print(fDist.max())\n",
    "print(fDist.most_common(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 9), ('and', 8), ('.', 8), ('the', 7), ('of', 5)]\n"
     ]
    }
   ],
   "source": [
    "Freq_dist = nltk.FreqDist(word_list)\n",
    "print(Freq_dist.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "\n",
      " List of words after removing stop words \n",
      " ['Trump', 'born', 'raised', 'New', 'York', 'City', 'borough', 'Queens', ',', 'received', 'economics', 'degree', 'Wharton', 'School', 'University', 'Pennsylvania', '.', 'He', 'took', 'charge', 'family', \"'s\", 'real', 'estate', 'business', '1971', ',', 'renamed', 'The', 'Trump', 'Organization', ',', 'expanded', 'Manhattan', '.', 'The', 'company', 'built', 'renovated', 'skyscrapers', ',', 'hotels', ',', 'casinos', ',', 'golf', 'courses', '.', 'Trump', 'later', 'started', 'various', 'side', 'ventures', ',', 'including', 'licensing', 'name', 'real', 'estate', 'consumer', 'products', '.', 'He', 'managed', 'company', '2017', 'inauguration', '.', 'He', 'co-authored', 'several', 'books', ',', 'including', 'The', 'Art', 'Deal', '.', 'He', 'owned', 'Miss', 'Universe', 'Miss', 'USA', 'beauty', 'pageants', '1996', '2015', ',', 'produced', 'hosted', 'reality', 'television', 'show', 'The', 'Apprentice', '2003', '2015', '.', 'Forbes', 'estimates', 'net', 'worth', '$', '3.1', 'billion', '.']\n",
      "\n",
      " List of most common words \n",
      " [(',', 9), ('.', 8), ('He', 4), ('The', 4), ('Trump', 3)]\n",
      "['Trump', 'born', 'raised', 'New', 'York', 'City', 'borough', 'Queens', ',', 'received', 'economics', 'degree', 'Wharton', 'School', 'University', 'Pennsylvania', '.', 'He', 'took', 'charge', 'family', \"'s\", 'real', 'estate', 'business', '1971', ',', 'renamed', 'The', 'Trump', 'Organization', ',', 'expanded', 'Manhattan', '.', 'The', 'company', 'built', 'renovated', 'skyscrapers', ',', 'hotels', ',', 'casinos', ',', 'golf', 'courses', '.', 'Trump', 'later', 'started', 'various', 'side', 'ventures', ',', 'including', 'licensing', 'name', 'real', 'estate', 'consumer', 'products', '.', 'He', 'managed', 'company', '2017', 'inauguration', '.', 'He', 'co-authored', 'several', 'books', ',', 'including', 'The', 'Art', 'Deal', '.', 'He', 'owned', 'Miss', 'Universe', 'Miss', 'USA', 'beauty', 'pageants', '1996', '2015', ',', 'produced', 'hosted', 'reality', 'television', 'show', 'The', 'Apprentice', '2003', '2015', '.', 'Forbes', 'estimates', 'net', 'worth', '$', '3.1', 'billion', '.']\n",
      "\n",
      "List of most common words  [(',', 9), ('.', 8), ('He', 4), ('The', 4), ('Trump', 3)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words=stopwords.words(\"english\") # you may also try french, german\n",
    "print (stop_words)\n",
    "\n",
    "sample_text='''\n",
    "Trump was born and raised in the New York City borough of Queens,\n",
    "and received an economics degree from the Wharton School of the University of\n",
    "Pennsylvania. He took charge of his family's real estate business in 1971,\n",
    "renamed it to The Trump Organization, and expanded it into Manhattan.\n",
    "The company built or renovated skyscrapers, hotels, casinos, and golf courses.\n",
    "Trump later started various side ventures, including licensing his name\n",
    "for real estate and consumer products. He managed the company until his\n",
    "2017 inauguration. He co-authored several books, including The Art of the Deal.\n",
    "He owned the Miss Universe and Miss USA beauty pageants from 1996 to 2015,\n",
    "and he produced and hosted the reality television show The Apprentice from\n",
    "2003 to 2015. Forbes estimates his net worth to be $3.1 billion. \n",
    "'''\n",
    "filtered_sample=[]\n",
    "words=word_tokenize(sample_text)\n",
    "\n",
    "for i in words:\n",
    "    if i not in stop_words:\n",
    "       filtered_sample.append(i)\n",
    "    \n",
    "print(\"\\n List of words after removing stop words \\n\", filtered_sample)\n",
    "\n",
    "fdist=nltk.FreqDist(filtered_sample)\n",
    "print(\"\\n List of most common words \\n\", fdist.most_common(5))\n",
    "\n",
    "filter_list2 = [w for w in words if not w in stop_words]\n",
    "f_dist2 = nltk.FreqDist(filter_list2)\n",
    "#print(filter_list2)\n",
    "print(\"\\nList of most common words \", f_dist2.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trump', 'born', 'raised', 'New', 'York', 'City', 'borough', 'Queens', 'received', 'economics', 'degree', 'Wharton', 'School', 'University', 'Pennsylvania', 'He', 'took', 'charge', 'family', \"'s\", 'real', 'estate', 'business', '1971', 'renamed', 'The', 'Trump', 'Organization', 'expanded', 'Manhattan', 'The', 'company', 'built', 'renovated', 'skyscrapers', 'hotels', 'casinos', 'golf', 'courses', 'Trump', 'later', 'started', 'various', 'side', 'ventures', 'including', 'licensing', 'name', 'real', 'estate', 'consumer', 'products', 'He', 'managed', 'company', '2017', 'inauguration', 'He', 'co-authored', 'several', 'books', 'including', 'The', 'Art', 'Deal', 'He', 'owned', 'Miss', 'Universe', 'Miss', 'USA', 'beauty', 'pageants', '1996', '2015', 'produced', 'hosted', 'reality', 'television', 'show', 'The', 'Apprentice', '2003', '2015', 'Forbes', 'estimates', 'net', 'worth', '3.1', 'billion']\n",
      "\n",
      "Most common top 10 words [('He', 4), ('The', 4), ('Trump', 3), ('real', 2), ('estate', 2), ('company', 2), ('including', 2), ('Miss', 2), ('2015', 2), ('born', 1)]\n"
     ]
    }
   ],
   "source": [
    "filter_list3 = [w for w in words if not w in stop_words and not w in string.punctuation]\n",
    "print(filter_list3)\n",
    "\n",
    "f_dist3 = nltk.FreqDist(filter_list3)\n",
    "print(\"\\nMost common top 10 words\",f_dist3.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game\n",
      "game\n",
      "game\n",
      "game\n",
      "learn\n",
      "learn\n",
      "learn\n",
      "learn\n"
     ]
    }
   ],
   "source": [
    "## Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "text = ['game', 'gaming', 'games','gamed']\n",
    "text2 = ['learn', 'learned', 'learning', 'learns']\n",
    "text3 = ['do', 'does', 'did', 'done']\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for i in text:\n",
    "    print(ps.stem(i))\n",
    "\n",
    "for i in text2:\n",
    "    print(ps.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n",
      "\n",
      "\n",
      "\n",
      "fli gener die mule die agre own meet item tradit refer\n",
      "fli generous die mule die agre own meet item tradit refer\n",
      "fli gen die mul died agree own meet item tradit ref\n",
      "fly generously dy mule died agreed owned meeting itemization traditional reference\n"
     ]
    }
   ],
   "source": [
    "# try out other stemmers\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "print(\" \".join(SnowballStemmer.languages))\n",
    "plurals = ['flies','generously','dies','mules',\n",
    "'died', 'agreed', 'owned','meeting','itemization',\n",
    "'traditional','reference']\n",
    "\n",
    "stemmer1=PorterStemmer()\n",
    "stemmer2=SnowballStemmer(\"english\")\n",
    "stemmer3 = nltk.LancasterStemmer()\n",
    "stemmer4=nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "singles1=[stemmer1.stem(plural) for plural in plurals]\n",
    "singles2=[stemmer2.stem(plural) for plural in plurals]\n",
    "singles3=[stemmer3.stem(plural) for plural in plurals]\n",
    "singles4=[stemmer4.lemmatize(plural) for plural in plurals]\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(' '.join(singles1))\n",
    "print(' '.join(singles2)) \n",
    "print(' '.join(singles3))\n",
    "print(' '.join(singles4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Part', 'NN'), ('of', 'IN'), ('Speech', 'NNP'), ('tagging', 'NN'), ('does', 'VBZ'), ('exactly', 'RB'), ('what', 'WP'), ('it', 'PRP'), ('sounds', 'VBZ'), ('like', 'IN'), (',', ','), ('it', 'PRP'), ('tags', 'VBZ'), ('each', 'DT'), ('word', 'NN'), ('in', 'IN'), ('a', 'DT'), ('sentence', 'NN'), ('with', 'IN'), ('the', 'DT'), ('part', 'NN'), ('of', 'IN'), ('speech', 'NN'), ('for', 'IN'), ('that', 'DT'), ('word', 'NN'), ('.', '.')]\n",
      "[('This', 'DT'), ('means', 'VBZ'), ('it', 'PRP'), ('labels', 'VBZ'), ('words', 'NNS'), ('as', 'IN'), ('noun', 'NN'), (',', ','), ('adjective', 'JJ'), (',', ','), ('verb', 'NN'), (',', ','), ('etc', 'FW'), ('.', '.')]\n",
      "[('PoS', 'NNP'), ('tagging', 'VBG'), ('also', 'RB'), ('covers', 'VBZ'), ('tenses', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('parts', 'NNS'), ('of', 'IN'), ('speech', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sample=\"Part of Speech tagging does exactly what it sounds like, it tags each word in a sentence with the part of speech for that word. This means it labels words as noun, adjective, verb, etc. PoS tagging also covers tenses of the parts of speech.\"\n",
    "\n",
    "tokenized=nltk.sent_tokenize(sample) #Tokenize the corpora into sentences\n",
    "for i in tokenized:\n",
    "    words=nltk.word_tokenize(i) #Tokenzie each sentence into words\n",
    "    tagged=nltk.pos_tag(words) #tag the words\n",
    "    print (tagged) # output is a list of tuples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
